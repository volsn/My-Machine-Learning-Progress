{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = 7, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=67, shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(np.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       "array([[ 0.12979013,  0.34936082,  0.11743969, -0.36701852, -0.41630742,\n",
       "        -0.1935587 ,  0.41698426, -0.11632597,  0.5922645 ,  0.08142054],\n",
       "       [ 0.5635398 ,  0.01603025, -0.09774065,  0.11137617,  0.13131154,\n",
       "         0.35417205, -0.16789287, -0.2778934 ,  0.39161927, -0.07140529],\n",
       "       [ 0.44506747, -0.51597047, -0.18949264, -0.05792612,  0.2784546 ,\n",
       "         0.19722027,  0.5458626 , -0.25213605, -0.04296994,  0.5016801 ],\n",
       "       [-0.2589909 ,  0.1977722 , -0.29398713, -0.11125237, -0.5226159 ,\n",
       "        -0.3078582 ,  0.30679727,  0.4924801 ,  0.01447982, -0.00605464],\n",
       "       [-0.17914036,  0.5834914 ,  0.32613277, -0.36287045, -0.61158794,\n",
       "         0.2849838 ,  0.49837786, -0.30735773, -0.37366727, -0.5059478 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[ 0.12979013,  0.34936082,  0.11743969, -0.36701852, -0.41630742,\n",
       "         -0.1935587 ,  0.41698426, -0.11632597,  0.5922645 ,  0.08142054],\n",
       "        [ 0.5635398 ,  0.01603025, -0.09774065,  0.11137617,  0.13131154,\n",
       "          0.35417205, -0.16789287, -0.2778934 ,  0.39161927, -0.07140529],\n",
       "        [ 0.44506747, -0.51597047, -0.18949264, -0.05792612,  0.2784546 ,\n",
       "          0.19722027,  0.5458626 , -0.25213605, -0.04296994,  0.5016801 ],\n",
       "        [-0.2589909 ,  0.1977722 , -0.29398713, -0.11125237, -0.5226159 ,\n",
       "         -0.3078582 ,  0.30679727,  0.4924801 ,  0.01447982, -0.00605464],\n",
       "        [-0.17914036,  0.5834914 ,  0.32613277, -0.36287045, -0.61158794,\n",
       "          0.2849838 ,  0.49837786, -0.30735773, -0.37366727, -0.5059478 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\"kernel\",\n",
    "                                        shape=[int(input_shape[-1]),\n",
    "                                               self.num_outputs])\n",
    "        self.bias = self.add_variable(\"bias\",\n",
    "                                      shape=[self.num_outputs])\n",
    "        \n",
    "    def call(self, input):\n",
    "        return tf.add(tf.matmul(input, self.kernel), self.bias)\n",
    "    \n",
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_dense_layer_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = layer(np.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Variables:\n",
      "my_dense_layer_7/kernel:0\n",
      "my_dense_layer_7/bias:0\n"
     ]
    }
   ],
   "source": [
    "print('Trainable Variables:\\n', '\\n'.join([var.name for var in layer.trainable_variables]), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "        \n",
    "        self.conv2a = layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2b = layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2c = layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "        \n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer resnet_identity_block_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = block(np.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0xb33d3a630>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0xb33d3aa90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb33d3add8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0xb33d2b358>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0xb33d2b6a0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0xb33d2bb70>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc multiple                  8         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc multiple                  12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2387, shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (1, 1),input_shape=(None, None, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(2, 1,padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(3, (1, 1)),\n",
    "    layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 27.273809523809526\n",
      "Bias: -26.35714285714286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NumPy Implementation\n",
    "# Input\n",
    "x = np.array([1,2,3,4,5,6,7,8])\n",
    "y = np.array([15,32,66,45,90,153,170,200])\n",
    "\n",
    "# Slope\n",
    "m = (len(x) * np.sum(x*y) - np.sum(x) * np.sum(y)) / (len(x)*np.sum(x*x) - np.sum(x) ** 2)\n",
    "    \n",
    "# Bias\n",
    "b = (np.sum(y) - m *np.sum(x)) / len(x)\n",
    "\n",
    "print('Slope: {}\\n'.format(m), 'Bias: {}\\n'.format(b), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.title('Linear Regression`s Input')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__(name='')\n",
    "        \n",
    "    def call(self, input_tensor, trainable=False):\n",
    "        x = input_tensor[:,0].numpy()\n",
    "        y = input_tensor[:,1].numpy()\n",
    "        self.slope = (len(x) * np.sum(x*y) - np.sum(x) * np.sum(y)) / (len(x)*np.sum(x*x) - np.sum(x) ** 2)\n",
    "        self.bias = (np.sum(y) - m *np.sum(x)) / len(x)\n",
    "        \n",
    "        return (self.slope, self.bias)\n",
    "    \n",
    "LinearRegression = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 15], [2, 32], [3, 66], [4, 45], [5, 90], [6, 153], [7, 170], [8, 200]]\n",
    "input_tensor = tf.convert_to_tensor(data, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.273809523809526 -26.35714285714286\n"
     ]
    }
   ],
   "source": [
    "m, b = LinearRegression(input_tensor)\n",
    "print(m, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
